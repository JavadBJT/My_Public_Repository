{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tJmTlAND5vcP"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "################################Libraries#############################\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "#################################Setting############################\n",
        "Discourse_Pharases = [\"you know \", \"I mean \", \"I think \", \"I guess\"]\n",
        "Affirmation_Words = [\"yeh\", \"uhum\", \"yep\", \"well\", \"like\",\"uh-huh\"]\n",
        "\n",
        "############################Functions################################\n",
        "def remove_Affirmative_repetitive_words(Affirmation_Words,text):\n",
        "    words = text.split()\n",
        "    words = [word for word in words if word not in Affirmation_Words]\n",
        "    new_words = []\n",
        "    prev_word = None\n",
        "    for word in words:\n",
        "        if word != prev_word:\n",
        "            new_words.append(word)\n",
        "            prev_word = word\n",
        "    return ' '.join(new_words)\n",
        "\n",
        "def remove_redundant_phrases(text,phrases_to_remove):\n",
        "    # Parse the text with SpaCy\n",
        "    #with open(\"/content/input.txt\", \"r\") as input_file:\n",
        "    #    text = input_file.read()\n",
        "    doc = nlp(text)\n",
        "    \n",
        "    # Loop over sentences\n",
        "    output = []\n",
        "    for sent in doc.sents:\n",
        "        sent_text = sent.text\n",
        "        # Remove undesired phrases in each sentence\n",
        "        for phrase in phrases_to_remove:\n",
        "            sent_text = sent_text.replace(phrase, '')\n",
        "        output.append(sent_text.strip())\n",
        "        \n",
        "    return ' '.join(output)\n",
        "\n",
        "###############Main#############################################\n",
        "\n",
        "with open(\"/content/input.txt\", \"r\") as input_file:\n",
        "    input_text = input_file.read()\n",
        "output_text = remove_Affirmative_repetitive_words(Affirmation_Words,input_text)\n",
        "cleaned_text = remove_redundant_phrases(output_text,Discourse_Pharases)\n",
        "\n",
        "\n",
        "with open(\"/content/output.txt\", \"w\") as output_file:\n",
        "    output_file.write(cleaned_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uaKIkrdyBx9D"
      }
    }
  ]
}